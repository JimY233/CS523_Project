{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /usr3/graduate/jiamingy/.local/lib/python3.8/site-packages (0.4.9)\n",
      "Requirement already satisfied: torchvision in /share/pkg.7/pytorch/1.8.1/install/lib/python3.8/site-packages (from timm) (0.9.1+cu111)\n",
      "Requirement already satisfied: torch>=1.4 in /share/pkg.7/pytorch/1.8.1/install/lib/python3.8/site-packages (from timm) (1.8.1+cu111)\n",
      "Requirement already satisfied: numpy in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/numpy-1.19.4-py3.8-linux-x86_64.egg (from torchvision->timm) (1.19.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from torchvision->timm) (8.0.1)\n",
      "Requirement already satisfied: typing-extensions in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from torch>=1.4->timm) (3.7.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None, augment=False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img = np.array(self.images[idx])\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx]).type(torch.long)\n",
    "        sample = (img, label)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "def load_data(path='datasets/fer2013/fer2013.csv'):\n",
    "    fer2013 = pd.read_csv(path)\n",
    "    emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
    "\n",
    "    return fer2013, emotion_mapping\n",
    "\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling\n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "\n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "\n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "\n",
    "    return image_array, image_label\n",
    "\n",
    "def get_dataloaders(path='datasets/fer2013/fer2013.csv', bs=64, augment=True):\n",
    "    \"\"\" Prepare train, val, & test dataloaders\n",
    "        Augment training data using:\n",
    "            - cropping\n",
    "            - shifting (vertical/horizental)\n",
    "            - horizental flipping\n",
    "            - rotation\n",
    "\n",
    "        input: path to fer2013 csv file\n",
    "        output: (Dataloader, Dataloader, Dataloader) \"\"\"\n",
    "\n",
    "    fer2013, emotion_mapping = load_data(path)\n",
    "\n",
    "    xtrain, ytrain = prepare_data(fer2013[fer2013['Usage'] == 'Training'])\n",
    "    xval, yval = prepare_data(fer2013[fer2013['Usage'] == 'PrivateTest'])\n",
    "    xtest, ytest = prepare_data(fer2013[fer2013['Usage'] == 'PublicTest'])\n",
    "\n",
    "    mu, st = 0, 255\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        # transforms.Scale(52),\n",
    "        transforms.TenCrop(40),\n",
    "        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "        transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors])),\n",
    "    ])\n",
    "\n",
    "    if augment:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(48, scale=(0.8, 1.2)),\n",
    "            transforms.RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([transforms.RandomRotation(10)], p=0.5),\n",
    "\n",
    "            transforms.TenCrop(40),\n",
    "            transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "            transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors])),\n",
    "            transforms.Lambda(lambda tensors: torch.stack([transforms.RandomErasing(p=0.5)(t) for t in tensors])),\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = test_transform\n",
    "\n",
    "    # X = np.vstack((xtrain, xval))\n",
    "    # Y = np.hstack((ytrain, yval))\n",
    "\n",
    "    train = CustomDataset(xtrain, ytrain, train_transform)\n",
    "    val = CustomDataset(xval, yval, test_transform)\n",
    "    test = CustomDataset(xtest, ytest, test_transform)\n",
    "\n",
    "    trainloader = DataLoader(train, batch_size=bs, shuffle=True, num_workers=2)\n",
    "    valloader = DataLoader(val, batch_size=64, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(test, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "    return trainloader, valloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save(net, logger, hps, epoch):\n",
    "    # Create the path the checkpint will be saved at using the epoch number\n",
    "    path = os.path.join(hps['model_save_dir'], 'epoch_' + str(epoch))\n",
    "\n",
    "    # create a dictionary containing the logger info and model info that will be saved\n",
    "    checkpoint = {\n",
    "        'logs': logger.get_logs(),\n",
    "        'params': net.state_dict()\n",
    "    }\n",
    "\n",
    "    # save checkpoint\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "def restore(net, logger, hps):\n",
    "    \"\"\" Load back the model and logger from a given checkpoint\n",
    "        epoch detailed in hps['restore_epoch'], if available\"\"\"\n",
    "    path = os.path.join(hps['model_save_dir'], 'epoch_' + str(hps['restore_epoch']))\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            checkpoint = torch.load(path)\n",
    "\n",
    "            logger.restore_logs(checkpoint['logs'])\n",
    "            net.load_state_dict(checkpoint['params'])\n",
    "            print(\"Network Restored!\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Restore Failed! Training from scratch.\")\n",
    "            print(e)\n",
    "            hps['start_epoch'] = 0\n",
    "\n",
    "    else:\n",
    "        print(\"Restore point unavailable. Training from scratch.\")\n",
    "        hps['start_epoch'] = 0\n",
    "\n",
    "\n",
    "def load_features(model, params):\n",
    "    \"\"\" Load params into all layers of 'model'\n",
    "        that are compatible, then freeze them\"\"\"\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    imp_params = {k: v for k, v in params.items() if k in model_dict}\n",
    "\n",
    "    # Load layers\n",
    "    model_dict.update(imp_params)\n",
    "    model.load_state_dict(imp_params)\n",
    "\n",
    "    # Freeze layers\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = {\n",
    "    'network': 'vgg',  # which network do you want to train\n",
    "    'name': 'myvgg',  # whatever you want to name your run\n",
    "    'n_epochs': 100,\n",
    "    'model_save_dir': None,  # where will checkpoints be stored (path created automatically using hps[name])\n",
    "    'restore_epoch': None,  # continue training from a specific saved point\n",
    "    'start_epoch': 0,\n",
    "    'lr': 0.01,  # starting learning rate\n",
    "    'save_freq': 20,  # how often to create checkpoints\n",
    "    'drop': 0.1,\n",
    "    'bs': 64,\n",
    "}\n",
    "hps['model_save_dir'] = os.path.join(os.getcwd(), 'checkpoints2', hps['name'])\n",
    "\n",
    "if not os.path.exists(hps['model_save_dir']):\n",
    "    os.makedirs(hps['model_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(net, dataloader, criterion, optimizer, scaler, Ncrop=True):\n",
    "    net = net.train()\n",
    "    loss_tr, correct_count, n_samples = 0.0, 0.0, 0.0\n",
    "    iters = len(dataloader)  # number of batches, not images\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with autocast():\n",
    "            if Ncrop:\n",
    "                # fuse crops and batchsize\n",
    "                bs, ncrops, c, h, w = inputs.shape\n",
    "                inputs = inputs.view(-1, c, h, w)\n",
    "\n",
    "            # repeat labels ncrops times\n",
    "            labels = torch.repeat_interleave(labels, repeats=ncrops, dim=0)\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            # scheduler.step(epoch + i / iters)\n",
    "\n",
    "            # calculate performance metrics\n",
    "            loss_tr += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            correct_count += (preds == labels).sum().item()\n",
    "            n_samples += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct_count / n_samples\n",
    "    loss = loss_tr / n_samples\n",
    "\n",
    "    return acc, loss\n",
    "\n",
    "\n",
    "def evaluate(net, dataloader, criterion, Ncrop=True):\n",
    "    net = net.eval()\n",
    "    loss_tr, correct_count, n_samples = 0.0, 0.0, 0.0\n",
    "    for data in dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        if Ncrop:\n",
    "            # fuse crops and batchsize\n",
    "            bs, ncrops, c, h, w = inputs.shape\n",
    "            inputs = inputs.view(-1, c, h, w)\n",
    "            # forward\n",
    "            outputs = net(inputs)\n",
    "            # combine results across the crops\n",
    "            outputs = outputs.view(bs, ncrops, -1)\n",
    "            outputs = torch.sum(outputs, dim=1) / ncrops\n",
    "        else:\n",
    "            outputs = net(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # calculate performance metrics\n",
    "        loss_tr += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        correct_count += (preds == labels).sum().item()\n",
    "        n_samples += labels.size(0)\n",
    "\n",
    "    acc = 100 * correct_count / n_samples\n",
    "    loss = loss_tr / n_samples\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.loss_train = []\n",
    "        self.loss_val = []\n",
    "\n",
    "        self.acc_train = []\n",
    "        self.acc_val = []\n",
    "\n",
    "    def get_logs(self):\n",
    "        return self.loss_train, self.loss_val, self.acc_train, self.acc_val\n",
    "\n",
    "    def restore_logs(self, logs):\n",
    "        self.loss_train, self.loss_val, self.acc_train, self.acc_val = logs\n",
    "\n",
    "    def save_plt(self, hps):\n",
    "        loss_path = os.path.join(hps['model_save_dir'], 'loss.jpg')\n",
    "        acc_path = os.path.join(hps['model_save_dir'], 'acc.jpg')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.acc_train, 'g', label='Training Acc')\n",
    "        plt.plot(self.acc_val, 'b', label='Validation Acc')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Acc')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(acc_path)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(self.loss_train, 'g', label='Training Loss')\n",
    "        plt.plot(self.loss_val, 'b', label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.savefig(loss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "class VggFeatures(nn.Module):\n",
    "    def __init__(self, drop=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1a = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv1b = nn.Conv2d(64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv2a = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        self.conv3a = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, 3, padding=1)\n",
    "\n",
    "        self.conv4a = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv4b = nn.Conv2d(512, 512, 3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bn1a = nn.BatchNorm2d(64)\n",
    "        self.bn1b = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.bn2a = nn.BatchNorm2d(128)\n",
    "        self.bn2b = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.bn3a = nn.BatchNorm2d(256)\n",
    "        self.bn3b = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.bn4a = nn.BatchNorm2d(512)\n",
    "        self.bn4b = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.lin1 = nn.Linear(512 * 2 * 2, 4096)\n",
    "        self.lin2 = nn.Linear(4096, 4096)\n",
    "\n",
    "        self.drop = nn.Dropout(p=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1a(self.conv1a(x)))\n",
    "        x = F.relu(self.bn1b(self.conv1b(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn2a(self.conv2a(x)))\n",
    "        x = F.relu(self.bn2b(self.conv2b(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn3a(self.conv3a(x)))\n",
    "        x = F.relu(self.bn3b(self.conv3b(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.bn4a(self.conv4a(x)))\n",
    "        x = F.relu(self.bn4b(self.conv4b(x)))\n",
    "        x = self.pool(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = x.view(-1, 512 * 2 * 2)\n",
    "        x = F.relu(self.drop(self.lin1(x)))\n",
    "        x = F.relu(self.drop(self.lin2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Vgg(VggFeatures):\n",
    "    def __init__(self, drop=0.2):\n",
    "        super().__init__(drop)\n",
    "        self.lin3 = nn.Linear(4096, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        x = self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models import vgg, efn\n",
    "#nets = {\n",
    "#    'vgg': vgg.Vgg,\n",
    "#    'efn': efn.EfficientNet\n",
    "#}\n",
    "\n",
    "\n",
    "def setup_network(hps):\n",
    "    #net = nets[hps['network']]()\n",
    "    net = Vgg()\n",
    "\n",
    "    # Prepare logger\n",
    "    logger = Logger()\n",
    "    if hps['restore_epoch']:\n",
    "        restore(net, logger, hps)\n",
    "\n",
    "    return logger, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(net, logger, hps):\n",
    "    # Create dataloaders\n",
    "    trainloader, valloader, testloader = get_dataloaders(bs=hps['bs'])\n",
    "\n",
    "    net = net.to(device)\n",
    "\n",
    "    learning_rate = float(hps['lr'])\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # optimizer = torch.optim.Adadelta(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    # optimizer = torch.optim.Adagrad(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    # optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=0.0001, amsgrad=True)\n",
    "    # optimizer = torch.optim.ASGD(net.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.75, patience=5, verbose=True)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 20, gamma=0.5, last_epoch=-1, verbose=True)\n",
    "    # scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(trainloader), epochs=hps['n_epochs'])\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1, verbose=True)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6, last_epoch=-1, verbose=False)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    print(\"Training\", hps['name'], \"on\", device)\n",
    "    for epoch in range(hps['start_epoch'], hps['n_epochs']):\n",
    "\n",
    "        acc_tr, loss_tr = train(net, trainloader, criterion, optimizer, scaler)\n",
    "        logger.loss_train.append(loss_tr)\n",
    "        logger.acc_train.append(acc_tr)\n",
    "\n",
    "        acc_v, loss_v = evaluate(net, valloader, criterion)\n",
    "        logger.loss_val.append(loss_v)\n",
    "        logger.acc_val.append(acc_v)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(acc_v)\n",
    "\n",
    "        if acc_v > best_acc:\n",
    "            best_acc = acc_v\n",
    "\n",
    "            save(net, logger, hps, epoch + 1)\n",
    "            logger.save_plt(hps)\n",
    "\n",
    "        if (epoch + 1) % hps['save_freq'] == 0:\n",
    "            save(net, logger, hps, epoch + 1)\n",
    "            logger.save_plt(hps)\n",
    "\n",
    "        print('Epoch %2d' % (epoch + 1),\n",
    "              'Train Accuracy: %2.4f %%' % acc_tr,\n",
    "              'Val Accuracy: %2.4f %%' % acc_v,\n",
    "              sep='\\t\\t')\n",
    "\n",
    "    # Calculate performance on test set\n",
    "    acc_test, loss_test = evaluate(net, testloader, criterion)\n",
    "    print('Test Accuracy: %2.4f %%' % acc_test,\n",
    "          'Test Loss: %2.6f' % loss_test,\n",
    "          sep='\\t\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vgg(\n",
       "  (conv1a): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2b): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3a): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3b): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4a): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4b): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bn1a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn1b): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2a): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2b): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3a): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3b): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4b): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (lin1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "  (lin2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (lin3): Linear(in_features=4096, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger, net = setup_network(hps)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training myvgg on cuda:0\n",
      "Epoch  1\t\tTrain Accuracy: 33.1830 %\t\tVal Accuracy: 44.7478 %\n",
      "Epoch  2\t\tTrain Accuracy: 47.3956 %\t\tVal Accuracy: 54.5556 %\n",
      "Epoch  3\t\tTrain Accuracy: 52.3369 %\t\tVal Accuracy: 57.2583 %\n",
      "Epoch  4\t\tTrain Accuracy: 54.9953 %\t\tVal Accuracy: 61.3541 %\n",
      "Epoch  5\t\tTrain Accuracy: 56.8271 %\t\tVal Accuracy: 61.0476 %\n",
      "Epoch  6\t\tTrain Accuracy: 58.1845 %\t\tVal Accuracy: 60.9083 %\n",
      "Epoch  7\t\tTrain Accuracy: 59.2556 %\t\tVal Accuracy: 62.2736 %\n",
      "Epoch  8\t\tTrain Accuracy: 60.2616 %\t\tVal Accuracy: 65.0042 %\n",
      "Epoch  9\t\tTrain Accuracy: 61.3100 %\t\tVal Accuracy: 61.9114 %\n",
      "Epoch 10\t\tTrain Accuracy: 62.3170 %\t\tVal Accuracy: 63.8897 %\n",
      "Epoch 11\t\tTrain Accuracy: 62.8158 %\t\tVal Accuracy: 61.0476 %\n",
      "Epoch 12\t\tTrain Accuracy: 63.5835 %\t\tVal Accuracy: 66.1466 %\n",
      "Epoch 13\t\tTrain Accuracy: 64.1645 %\t\tVal Accuracy: 66.0908 %\n",
      "Epoch 14\t\tTrain Accuracy: 64.9775 %\t\tVal Accuracy: 64.2519 %\n",
      "Epoch 15\t\tTrain Accuracy: 65.5627 %\t\tVal Accuracy: 69.1279 %\n",
      "Epoch 16\t\tTrain Accuracy: 66.2235 %\t\tVal Accuracy: 65.0320 %\n",
      "Epoch 17\t\tTrain Accuracy: 66.8310 %\t\tVal Accuracy: 67.6512 %\n",
      "Epoch 18\t\tTrain Accuracy: 67.2510 %\t\tVal Accuracy: 67.4561 %\n",
      "Epoch 19\t\tTrain Accuracy: 67.9588 %\t\tVal Accuracy: 68.8771 %\n",
      "Epoch 20\t\tTrain Accuracy: 68.4360 %\t\tVal Accuracy: 68.7099 %\n",
      "Epoch    21: reducing learning rate of group 0 to 7.5000e-03.\n",
      "Epoch 21\t\tTrain Accuracy: 69.2619 %\t\tVal Accuracy: 68.2641 %\n",
      "Epoch 22\t\tTrain Accuracy: 70.4939 %\t\tVal Accuracy: 68.5428 %\n",
      "Epoch 23\t\tTrain Accuracy: 71.1718 %\t\tVal Accuracy: 69.5737 %\n",
      "Epoch 24\t\tTrain Accuracy: 71.7493 %\t\tVal Accuracy: 69.4901 %\n",
      "Epoch 25\t\tTrain Accuracy: 72.1349 %\t\tVal Accuracy: 70.2703 %\n",
      "Epoch 26\t\tTrain Accuracy: 72.5048 %\t\tVal Accuracy: 70.3539 %\n",
      "Epoch 27\t\tTrain Accuracy: 73.1941 %\t\tVal Accuracy: 68.4592 %\n",
      "Epoch 28\t\tTrain Accuracy: 73.6323 %\t\tVal Accuracy: 68.9329 %\n",
      "Epoch 29\t\tTrain Accuracy: 74.0322 %\t\tVal Accuracy: 69.3787 %\n",
      "Epoch 30\t\tTrain Accuracy: 74.6027 %\t\tVal Accuracy: 70.4932 %\n",
      "Epoch 31\t\tTrain Accuracy: 74.9462 %\t\tVal Accuracy: 65.6729 %\n",
      "Epoch 32\t\tTrain Accuracy: 75.2907 %\t\tVal Accuracy: 69.7130 %\n",
      "Epoch 33\t\tTrain Accuracy: 75.8675 %\t\tVal Accuracy: 70.5489 %\n",
      "Epoch 34\t\tTrain Accuracy: 76.5467 %\t\tVal Accuracy: 70.7161 %\n",
      "Epoch 35\t\tTrain Accuracy: 76.8087 %\t\tVal Accuracy: 70.2981 %\n",
      "Epoch 36\t\tTrain Accuracy: 77.1051 %\t\tVal Accuracy: 71.6077 %\n",
      "Epoch 37\t\tTrain Accuracy: 77.5286 %\t\tVal Accuracy: 71.3848 %\n",
      "Epoch 38\t\tTrain Accuracy: 77.9888 %\t\tVal Accuracy: 70.2981 %\n",
      "Epoch 39\t\tTrain Accuracy: 78.3531 %\t\tVal Accuracy: 70.2424 %\n",
      "Epoch 40\t\tTrain Accuracy: 78.8801 %\t\tVal Accuracy: 70.2703 %\n",
      "Epoch 41\t\tTrain Accuracy: 79.2278 %\t\tVal Accuracy: 71.0226 %\n",
      "Epoch    42: reducing learning rate of group 0 to 5.6250e-03.\n",
      "Epoch 42\t\tTrain Accuracy: 79.7875 %\t\tVal Accuracy: 70.8275 %\n",
      "Epoch 43\t\tTrain Accuracy: 81.2554 %\t\tVal Accuracy: 72.3321 %\n",
      "Epoch 44\t\tTrain Accuracy: 81.8632 %\t\tVal Accuracy: 71.6356 %\n",
      "Epoch 45\t\tTrain Accuracy: 82.0534 %\t\tVal Accuracy: 72.0256 %\n",
      "Epoch 46\t\tTrain Accuracy: 82.4351 %\t\tVal Accuracy: 70.7439 %\n",
      "Epoch 47\t\tTrain Accuracy: 82.9527 %\t\tVal Accuracy: 70.7997 %\n",
      "Epoch 48\t\tTrain Accuracy: 83.2990 %\t\tVal Accuracy: 72.1371 %\n",
      "Epoch    49: reducing learning rate of group 0 to 4.2188e-03.\n",
      "Epoch 49\t\tTrain Accuracy: 83.5222 %\t\tVal Accuracy: 72.1649 %\n",
      "Epoch 50\t\tTrain Accuracy: 84.7177 %\t\tVal Accuracy: 70.9111 %\n",
      "Epoch 51\t\tTrain Accuracy: 84.9848 %\t\tVal Accuracy: 71.5520 %\n",
      "Epoch 52\t\tTrain Accuracy: 85.4175 %\t\tVal Accuracy: 72.6665 %\n",
      "Epoch 53\t\tTrain Accuracy: 85.6324 %\t\tVal Accuracy: 72.7222 %\n",
      "Epoch 54\t\tTrain Accuracy: 85.9020 %\t\tVal Accuracy: 72.5272 %\n",
      "Epoch 55\t\tTrain Accuracy: 85.9393 %\t\tVal Accuracy: 73.1402 %\n",
      "Epoch 56\t\tTrain Accuracy: 86.2374 %\t\tVal Accuracy: 71.6634 %\n",
      "Epoch 57\t\tTrain Accuracy: 86.2709 %\t\tVal Accuracy: 72.3879 %\n",
      "Epoch 58\t\tTrain Accuracy: 86.4945 %\t\tVal Accuracy: 71.8306 %\n"
     ]
    }
   ],
   "source": [
    "run(net, logger, hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
